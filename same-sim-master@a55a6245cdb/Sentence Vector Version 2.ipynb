{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0045U\n",
      "0046U\n",
      "0047U\n",
      "0048U\n",
      "0049U\n",
      "0050U\n",
      "0051U\n",
      "0052U\n",
      "0053U\n",
      "0054U\n",
      "0055U\n",
      "0056U\n",
      "0057U\n",
      "0058U\n",
      "0059U\n",
      "0060U\n",
      "0061U\n",
      "0062U\n",
      "0063U\n",
      "0064U\n",
      "0065U\n",
      "0066U\n",
      "0067U\n",
      "0068U\n",
      "0069U\n",
      "0070U\n",
      "0071U\n",
      "0072U\n",
      "0073U\n",
      "0074U\n",
      "0075U\n",
      "0076U\n",
      "0077U\n",
      "0078U\n",
      "0079U\n",
      "0505T\n",
      "0506T\n",
      "0507T\n",
      "0508T\n",
      "0509T \n",
      "0510T \n",
      "0511T\n",
      "0512T\n",
      "0513T\n",
      "0514T\n",
      "0515T\n",
      "0516T\n",
      "0517T\n",
      "0518T\n",
      "0519T\n",
      "0520T\n",
      "0521T\n",
      "0522T\n",
      "0523T\n",
      "0524T\n",
      "0525T\n",
      "0526T\n",
      "0527T\n",
      "0528T\n",
      "0529T\n",
      "0530T\n",
      "0531T\n",
      "0532T\n",
      "0533T\n",
      "0534T\n",
      "0535T\n",
      "0536T\n",
      "0537T\n",
      "0538T\n",
      "0539T\n",
      "0540T\n",
      "0541T\n",
      "0542T\n",
      "10004\n",
      "10005\n",
      "10006\n",
      "10007\n",
      "10008\n",
      "10009\n",
      "10010\n",
      "10011\n",
      "10012\n",
      "11102\n",
      "11103\n",
      "11104\n",
      "11105\n",
      "11106\n",
      "11107\n",
      "20932\n",
      "20933\n",
      "20934\n",
      "27369\n",
      "33274\n",
      "33275\n",
      "33285\n",
      "33286\n",
      "33289\n",
      "33440\n",
      "33866\n",
      "36572\n",
      "36573\n",
      "38531\n",
      "43762\n",
      "43763\n",
      "50436\n",
      "50437\n",
      "53854\n",
      "76391\n",
      "76978\n",
      "76979\n",
      "76981\n",
      "76982\n",
      "76983\n",
      "77046\n",
      "77047\n",
      "77048\n",
      "77049\n",
      "81163\n",
      "81164\n",
      "81165\n",
      "81166\n",
      "81167\n",
      "81171\n",
      "81172\n",
      "81173\n",
      "81174\n",
      "81177\n",
      "81178\n",
      "81179\n",
      "81180\n",
      "81181\n",
      "81182\n",
      "81183\n",
      "81184\n",
      "81185\n",
      "81186\n",
      "81187\n",
      "81188\n",
      "81189\n",
      "81190\n",
      "81204\n",
      "81233\n",
      "81234\n",
      "81236\n",
      "81237\n",
      "81239\n",
      "81271\n",
      "81274\n",
      "81284\n",
      "81285\n",
      "81286\n",
      "81289\n",
      "81305\n",
      "81306\n",
      "81312\n",
      "81320\n",
      "81329\n",
      "81333\n",
      "81336\n",
      "81337\n",
      "81343\n",
      "81344\n",
      "81345\n",
      "81443\n",
      "81518\n",
      "81596\n",
      "82642\n",
      "83722\n",
      "90689\n",
      "92273\n",
      "92274\n",
      "93264\n",
      "95836\n",
      "95976\n",
      "95977\n",
      "95983\n",
      "95984\n",
      "96112\n",
      "96113\n",
      "96121\n",
      "96130\n",
      "96131\n",
      "96132\n",
      "96133\n",
      "96136\n",
      "96137\n",
      "96138\n",
      "96139\n",
      "96146\n",
      "97151\n",
      "97152\n",
      "97153\n",
      "97154\n",
      "97155\n",
      "97156\n",
      "97157\n",
      "97158\n",
      "99451\n",
      "99452\n",
      "99453\n",
      "99454\n",
      "99457\n",
      "99491\n",
      "A4563\n",
      "A5514\n",
      "A6460\n",
      "A6461\n",
      "C1823\n",
      "C8937\n",
      "C9015\n",
      "C9016\n",
      "C9029\n",
      "C9030\n",
      "C9031\n",
      "C9032\n",
      "C9033\n",
      "C9034\n",
      "C9035\n",
      "C9036\n",
      "C9037\n",
      "C9038\n",
      "C9039\n",
      "C9407\n",
      "C9408\n",
      "C9488\n",
      "C9738\n",
      "C9745\n",
      "C9746\n",
      "C9747\n",
      "C9748\n",
      "C9750\n",
      "C9751\n",
      "C9752\n",
      "C9753\n",
      "D0412\n",
      "D1516\n",
      "D1517\n",
      "D1526\n",
      "D1527\n",
      "D5282\n",
      "D5283\n",
      "D7979\n",
      "D9995\n",
      "E0447\n",
      "E0467\n",
      "G9890\n",
      "G9899\n",
      "G9900\n",
      "G9902\n",
      "G9904\n",
      "G9948\n",
      "G9949\n",
      "G9954\n",
      "G9955\n",
      "G9956\n",
      "G9978\n",
      "G9979\n",
      "G9980\n",
      "G9981\n",
      "G9982\n",
      "G9983\n",
      "G9984\n",
      "G9985\n",
      "G9986\n",
      "G9987\n",
      "J0584\n",
      "J0841\n",
      "J1746\n",
      "J2186\n",
      "J2787\n",
      "J3245\n",
      "J3397\n",
      "J3591\n",
      "J7177\n",
      "J7318\n",
      "J7329\n",
      "J9044\n",
      "L8608\n",
      "L8698\n",
      "L8701\n",
      "L8702\n",
      "Q5105\n",
      "Q5106\n",
      "Q5108\n",
      "Q5510\n",
      "Q9991\n",
      "Q9992\n",
      "Q9994\n",
      "Q9995\n",
      "T4545\n",
      "V5171\n",
      "V5172\n",
      "V5181\n",
      "V5211\n",
      "V5212\n",
      "V5213\n",
      "V5214\n",
      "V5215\n",
      "V5221\n",
      "A9513\n",
      "A9589\n",
      "B4105\n",
      "E0953\n",
      "J0185\n",
      "J0517\n",
      "J0567\n",
      "J0599\n",
      "J1301\n",
      "J1454\n",
      "J1628\n",
      "J2797\n",
      "J3304\n",
      "J3316\n",
      "J3398\n",
      "J7170\n",
      "J7203\n",
      "J9057\n",
      "J9153\n",
      "J9173\n",
      "J9229\n",
      "J9311\n",
      "Q9993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "\n",
    "mylist = list()\n",
    "InputSheet = \"Same-Sim-latestV1.csv\"\n",
    "MasterSheet = \"Same_SIM_Master_List.csv\"\n",
    "resultFrame = pd.DataFrame(columns=('NewCode','NewCodeDesc','SameSimCode', 'CPTDesc','Accuracy','Rank','Comments'),index=range(30000))\n",
    "rownum = -1\n",
    "NewCodeNum = -1\n",
    "\n",
    "def create_tokenizer_score(new_series, train_series, tokenizer):\n",
    "    \"\"\"\n",
    "    return the tf idf score of each possible pairs of documents\n",
    "    Args:\n",
    "        new_series (pd.Series): new data (To compare against train data)\n",
    "        train_series (pd.Series): train data (To fit the tf-idf transformer)\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "    train_tfidf = tokenizer.fit_transform(train_series)\n",
    "    \n",
    "    new_tfidf = tokenizer.transform(new_series)\n",
    "\n",
    "    X = pd.DataFrame(cosine_similarity(new_tfidf, train_tfidf), columns=train_series.index)\n",
    "    X['ix_new'] = new_series.index\n",
    "    score = pd.melt(\n",
    "        X,\n",
    "        id_vars='ix_new',\n",
    "        var_name='ix_train',\n",
    "        value_name='score'\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def Get_MasterCodeDesc():\n",
    "    df = pd.read_csv(MasterSheet)\n",
    "    sMasterCodeDesc = df['CPTLongDesc'].tolist()\n",
    "    return sMasterCodeDesc;\n",
    "\n",
    "def GetNewCPT():\n",
    "    NewCodeFrame = pd.read_csv(InputSheet,encoding ='latin1')\n",
    "    sNewCode = NewCodeFrame['HCPCS'].tolist()\n",
    "    return sNewCode;\n",
    "\n",
    "def GetNewCPTDesc():\n",
    "    NewCodeFrame = pd.read_csv(InputSheet,encoding ='latin1')\n",
    "    sNewCodeDesc = NewCodeFrame['LongDesc'].tolist()\n",
    "    return sNewCodeDesc;\n",
    "\n",
    "def GetSameSIMData():\n",
    "    SameSimDf = pd.read_csv(InputSheet,encoding ='latin1')\n",
    "    sNewCodeDesc = SameSimDf['SimCode'].tolist()\n",
    "    return sNewCodeDesc;\n",
    "   \n",
    "def textblob_tokenizer(str_input):\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words\n",
    "\n",
    "def GetRowNum(): \n",
    "    try:\n",
    "        rownum = resultFrame.loc[(resultFrame.Accuracy == '0003T') & (resultFrame.Rank == 'CERVICOGRAPY')].index[0]\n",
    "            #print(rownum)\n",
    "        resultFrame.loc[rownum,'Comments'] = \"Test\"\n",
    "    except:\n",
    "        \"No record found\"\n",
    "\n",
    "def GetMasterCPTCode(Val,NewCode,NewCodeDesc,Accuracy,RankNo,Comment,x):\n",
    "    df = pd.read_csv(MasterSheet)    \n",
    "    GetCPTValue = df.iloc[Val,0]\n",
    "    GetCPTDesc = df.iloc[Val,1]    \n",
    "    mylist.append(GetCPTValue)\n",
    "    mylist.append(GetCPTDesc)\n",
    "    resultFrame.loc[x].NewCode = NewCode\n",
    "    resultFrame.loc[x].SameSimCode = GetCPTValue\n",
    "    resultFrame.loc[x].CPTDesc = GetCPTDesc\n",
    "    resultFrame.loc[x].NewCodeDesc = NewCodeDesc\n",
    "    resultFrame.loc[x].Accuracy = Accuracy\n",
    "    resultFrame.loc[x].Rank = RankNo\n",
    "    resultFrame.loc[x].Comments = Comment\n",
    "    return mylist;\n",
    "\n",
    "#train_CPT_Set = pd.Series(GetMasterCPT())\n",
    "train_set = pd.Series(Get_MasterCodeDesc())\n",
    "NewCodeDescSet = pd.Series(GetNewCPTDesc())\n",
    "NewCodeSet = pd.Series(GetNewCPT())\n",
    "SameSimSet = pd.Series(GetSameSIMData())\n",
    "for i in NewCodeDescSet:\n",
    "    NewCodeNum = NewCodeNum+1\n",
    "    test_set = pd.Series(i)   \n",
    "    try:\n",
    "        rowFound = resultFrame.loc[(resultFrame.NewCode == NewCodeSet[NewCodeNum])].index[0]  \n",
    "        try:        \n",
    "            rowNumSameSimFound = resultFrame.loc[(resultFrame.NewCode == NewCodeSet[NewCodeNum]) & (resultFrame.SameSimCode == SameSimSet[NewCodeNum])].index[0]\n",
    "            resultFrame.loc[rowNumSameSimFound,'Comments'] = \"Present Both in MD and Autoproposal\"\n",
    "        except:\n",
    "            \"Not Found\"                                                                                   \n",
    "    except:\n",
    "        print(NewCodeSet[NewCodeNum])\n",
    "        #print(i)\n",
    "        test_set2 = word_tokenize(i)\n",
    "        #tokenizer = TfidfVectorizer(stop_words = 'english')# initiate here your own tokenizer (TfidfVectorizer, CountVectorizer, with stopwords...)\n",
    "        tokenizer = TfidfVectorizer()\n",
    "        score = create_tokenizer_score(train_series=train_set, new_series=test_set, tokenizer=tokenizer)\n",
    "        #score\n",
    "        pd.set_option(\"display.max_rows\", 11)\n",
    "        sortedscore = score.sort_values(by=['score'], ascending=False)\n",
    "        sortedscore.head(11)\n",
    "        ranknum = 0\n",
    "        found = \"false\"\n",
    "        for x in range(0,10):\n",
    "            ranknum = ranknum+1\n",
    "            df = pd.read_csv(MasterSheet) \n",
    "            svalue = sortedscore.iloc[x,1]\n",
    "            GetCPTValue = df.iloc[svalue,0]\n",
    "            if (GetCPTValue == SameSimSet[NewCodeNum]):\n",
    "                found = \"true\"\n",
    "                break \n",
    "\n",
    "        RecNum =0\n",
    "        for x in range(0,10):\n",
    "            rownum = rownum+1\n",
    "            svalue = sortedscore.iloc[x,1]\n",
    "            Accuracy = sortedscore.iloc[x,2]\n",
    "            \n",
    "            Comments = \"Present in Autoproposal\"\n",
    "\n",
    "            if (RecNum ==0):\n",
    "                result = GetMasterCPTCode(svalue,NewCodeSet[NewCodeNum],i,Accuracy*100,ranknum,Comments,rownum)\n",
    "            else:\n",
    "                result = GetMasterCPTCode(svalue,NewCodeSet[NewCodeNum],i,Accuracy*100,\"\",Comments,rownum)\n",
    "            RecNum =RecNum +1\n",
    "            \n",
    "        try:         \n",
    "            rowNumSameSimFound = resultFrame.loc[(resultFrame.NewCode == NewCodeSet[NewCodeNum]) & (resultFrame.SameSimCode == SameSimSet[NewCodeNum])].index[0]\n",
    "            resultFrame.loc[rowNumSameSimFound,'Comments'] = \"Present Both in MD and Autoproposal\"\n",
    "        except:\n",
    "            \"Not Found\"\n",
    "resultFrame\n",
    "\n",
    "export_csv = resultFrame.to_csv ('export_dataframe_V2.csv', index = None, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
