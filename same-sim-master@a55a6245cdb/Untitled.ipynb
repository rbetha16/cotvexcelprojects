{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "\n",
    "mylist = list()\n",
    "resultFrame = pd.DataFrame(columns=('NewCode','NewCodeDesc','SameSimCode', 'CPTDesc','Accuracy','Rank'),index=range(30000))\n",
    "rownum = -1\n",
    "NewCodeNum = -1\n",
    "\n",
    "def create_tokenizer_score(new_series, train_series, tokenizer):\n",
    "    \"\"\"\n",
    "    return the tf idf score of each possible pairs of documents\n",
    "    Args:\n",
    "        new_series (pd.Series): new data (To compare against train data)\n",
    "        train_series (pd.Series): train data (To fit the tf-idf transformer)\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "        \n",
    "    train_tfidf = tokenizer.fit_transform(train_series)\n",
    "    \n",
    "    new_tfidf = tokenizer.transform(new_series)\n",
    "\n",
    "    X = pd.DataFrame(cosine_similarity(new_tfidf, train_tfidf), columns=train_series.index)\n",
    "    X['ix_new'] = new_series.index\n",
    "    score = pd.melt(\n",
    "        X,\n",
    "        id_vars='ix_new',\n",
    "        var_name='ix_train',\n",
    "        value_name='score'\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def Get_MasterCodeDesc():\n",
    "    df = pd.read_csv(\"Same_SIM_Master_List.csv\")\n",
    "    sMasterCodeDesc = df['CPTLongDesc'].tolist()\n",
    "    return sMasterCodeDesc;\n",
    "\n",
    "def GetNewCPT():\n",
    "    NewCodeFrame = pd.read_csv(\"Same-Sim.csv\",encoding ='latin1')\n",
    "    sNewCode = NewCodeFrame['HCPCS'].tolist()\n",
    "    return sNewCode;\n",
    "\n",
    "def GetNewCPTDesc():\n",
    "    NewCodeFrame = pd.read_csv(\"Same-Sim.csv\",encoding ='latin1')\n",
    "    sNewCodeDesc = NewCodeFrame['LongDesc'].tolist()\n",
    "    return sNewCodeDesc;\n",
    "\n",
    "def GetSameSIMData():\n",
    "    SameSimDf = pd.read_csv(\"Same-Sim.csv\",encoding ='latin1')\n",
    "    sNewCodeDesc = SameSimDf['SimCode'].tolist()\n",
    "    return sNewCodeDesc;\n",
    "   \n",
    "def textblob_tokenizer(str_input):\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems\n",
    "\n",
    "def GetMasterCPTCode(Val,NewCode,NewCodeDesc,Accuracy,RankNo,x):\n",
    "    df = pd.read_csv(\"Same_SIM_Master_List.csv\")    \n",
    "    GetCPTValue = df.iloc[Val,0]\n",
    "    GetCPTDesc = df.iloc[Val,1]    \n",
    "    mylist.append(GetCPTValue)\n",
    "    mylist.append(GetCPTDesc)\n",
    "    resultFrame.loc[x].NewCode = NewCode\n",
    "    resultFrame.loc[x].SameSimCode = GetCPTValue\n",
    "    resultFrame.loc[x].CPTDesc = GetCPTDesc\n",
    "    resultFrame.loc[x].NewCodeDesc = NewCodeDesc\n",
    "    resultFrame.loc[x].Accuracy = Accuracy\n",
    "    resultFrame.loc[x].Rank = RankNo\n",
    "    return mylist;\n",
    "\n",
    "#train_CPT_Set = pd.Series(GetMasterCPT())\n",
    "train_set = pd.Series(Get_MasterCodeDesc())\n",
    "NewCodeDescSet = pd.Series(GetNewCPTDesc())\n",
    "NewCodeSet = pd.Series(GetNewCPT())\n",
    "SameSimSet = pd.Series(GetSameSIMData())\n",
    "\n",
    "    \n",
    "for i in NewCodeDescSet:\n",
    "    NewCodeNum = NewCodeNum+1\n",
    "    test_set = pd.Series(i)\n",
    "    #print(i)\n",
    "    tokenizer = TfidfVectorizer(tokenizer=tokenize,stop_words = 'english') # initiate here your own tokenizer (TfidfVectorizer, CountVectorizer, with stopwords...)\n",
    "    score = create_tokenizer_score(train_series=train_set, new_series=test_set, tokenizer=tokenizer)\n",
    "    #score\n",
    "    pd.set_option(\"display.max_rows\", 11)\n",
    "    sortedscore = score.sort_values(by=['score'], ascending=False)\n",
    "    sortedscore.head(11)\n",
    "    ranknum = 0\n",
    "    for x in range(0,10):\n",
    "        ranknum = ranknum+1\n",
    "        df = pd.read_csv(\"Same_SIM_Master_List.csv\") \n",
    "        svalue = sortedscore.iloc[x,1]\n",
    "        GetCPTValue = df.iloc[svalue,0]\n",
    "        if (GetCPTValue == SameSimSet[NewCodeNum]):\n",
    "            break \n",
    "    \n",
    "    RecNum =0\n",
    "    for x in range(0,10):\n",
    "        rownum = rownum+1\n",
    "        svalue = sortedscore.iloc[x,1]\n",
    "        Accuracy = sortedscore.iloc[x,2]        \n",
    "        if (RecNum ==0):\n",
    "            result = GetMasterCPTCode(svalue,NewCodeSet[NewCodeNum],i,Accuracy*100,ranknum,rownum)\n",
    "        else:\n",
    "            result = GetMasterCPTCode(svalue,NewCodeSet[NewCodeNum],i,Accuracy*100,\"\",rownum)\n",
    "        RecNum =RecNum +1\n",
    " \n",
    "resultFrame\n",
    "\n",
    "export_csv = resultFrame.to_csv ('export_dataframewithStemmingFull.csv', index = None, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fish']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob_tokenizer(\"fishes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "\n",
    "mylist = list()\n",
    "resultFrame = pd.DataFrame(columns=('NewCode','NewCodeDesc','SameSimCode', 'CPTDesc','Accuracy','Rank'),index=range(30000))\n",
    "rownum = -1\n",
    "NewCodeNum = -1\n",
    "\n",
    "def create_tokenizer_score(new_series, train_series, tokenizer):\n",
    "    \"\"\"\n",
    "    return the tf idf score of each possible pairs of documents\n",
    "    Args:\n",
    "        new_series (pd.Series): new data (To compare against train data)\n",
    "        train_series (pd.Series): train data (To fit the tf-idf transformer)\n",
    "    Returns:\n",
    "        pd.DataFrame\n",
    "    \"\"\"\n",
    "        \n",
    "    train_tfidf = tokenizer.fit_transform(train_series)\n",
    "    \n",
    "    new_tfidf = tokenizer.transform(new_series)\n",
    "\n",
    "    X = pd.DataFrame(cosine_similarity(new_tfidf, train_tfidf), columns=train_series.index)\n",
    "    X['ix_new'] = new_series.index\n",
    "    score = pd.melt(\n",
    "        X,\n",
    "        id_vars='ix_new',\n",
    "        var_name='ix_train',\n",
    "        value_name='score'\n",
    "    )\n",
    "    return score\n",
    "\n",
    "\n",
    "def Get_MasterCodeDesc():\n",
    "    df = pd.read_csv(\"Same_SIM_Master_List.csv\")\n",
    "    sMasterCodeDesc = df['CPTLongDesc'].tolist()\n",
    "    return sMasterCodeDesc;\n",
    "\n",
    "def GetNewCPT():\n",
    "    NewCodeFrame = pd.read_csv(\"Same-Sim_SAMPLE.csv\",encoding ='latin1')\n",
    "    sNewCode = NewCodeFrame['HCPCS'].tolist()\n",
    "    return sNewCode;\n",
    "\n",
    "def GetNewCPTDesc():\n",
    "    NewCodeFrame = pd.read_csv(\"Same-Sim_SAMPLE.csv\",encoding ='latin1')\n",
    "    sNewCodeDesc = NewCodeFrame['LongDesc'].tolist()\n",
    "    return sNewCodeDesc;\n",
    "\n",
    "def GetSameSIMData():\n",
    "    SameSimDf = pd.read_csv(\"Same-Sim_SAMPLE.csv\",encoding ='latin1')\n",
    "    sNewCodeDesc = SameSimDf['SimCode'].tolist()\n",
    "    return sNewCodeDesc;\n",
    "   \n",
    "def textblob_tokenizer(str_input):\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems\n",
    "\n",
    "def GetMasterCPTCode(Val,NewCode,NewCodeDesc,Accuracy,RankNo,x):\n",
    "    df = pd.read_csv(\"Same_SIM_Master_List.csv\")    \n",
    "    GetCPTValue = df.iloc[Val,0]\n",
    "    GetCPTDesc = df.iloc[Val,1]    \n",
    "    mylist.append(GetCPTValue)\n",
    "    mylist.append(GetCPTDesc)\n",
    "    resultFrame.loc[x].NewCode = NewCode\n",
    "    resultFrame.loc[x].SameSimCode = GetCPTValue\n",
    "    resultFrame.loc[x].CPTDesc = GetCPTDesc\n",
    "    resultFrame.loc[x].NewCodeDesc = NewCodeDesc\n",
    "    resultFrame.loc[x].Accuracy = Accuracy\n",
    "    resultFrame.loc[x].Rank = RankNo\n",
    "    return mylist;\n",
    "\n",
    "#train_CPT_Set = pd.Series(GetMasterCPT())\n",
    "train_set = pd.Series(Get_MasterCodeDesc())\n",
    "NewCodeDescSet = pd.Series(GetNewCPTDesc())\n",
    "NewCodeSet = pd.Series(GetNewCPT())\n",
    "SameSimSet = pd.Series(GetSameSIMData())\n",
    "\n",
    "    \n",
    "for i in NewCodeDescSet:\n",
    "    NewCodeNum = NewCodeNum+1\n",
    "    test_set = pd.Series(i)\n",
    "    #print(i)\n",
    "    tokenizer = TfidfVectorizer(stop_words = 'english') # initiate here your own tokenizer (TfidfVectorizer, CountVectorizer, with stopwords...)\n",
    "    score = create_tokenizer_score(train_series=train_set, new_series=test_set, tokenizer=tokenizer)\n",
    "    #score\n",
    "    pd.set_option(\"display.max_rows\", 11)\n",
    "    sortedscore = score.sort_values(by=['score'], ascending=False)\n",
    "    sortedscore.head(11)\n",
    "    ranknum = 0\n",
    "    for x in range(0,10):\n",
    "        ranknum = ranknum+1\n",
    "        df = pd.read_csv(\"Same_SIM_Master_List.csv\") \n",
    "        svalue = sortedscore.iloc[x,1]\n",
    "        GetCPTValue = df.iloc[svalue,0]\n",
    "        if (GetCPTValue == SameSimSet[NewCodeNum]):\n",
    "            break \n",
    "    \n",
    "    RecNum =0\n",
    "    for x in range(0,10):\n",
    "        rownum = rownum+1\n",
    "        svalue = sortedscore.iloc[x,1]\n",
    "        Accuracy = sortedscore.iloc[x,2]        \n",
    "        if (RecNum ==0):\n",
    "            result = GetMasterCPTCode(svalue,NewCodeSet[NewCodeNum],i,Accuracy*100,ranknum,rownum)\n",
    "        else:\n",
    "            result = GetMasterCPTCode(svalue,NewCodeSet[NewCodeNum],i,Accuracy*100,\"\",rownum)\n",
    "        RecNum =RecNum +1\n",
    " \n",
    "resultFrame\n",
    "\n",
    "export_csv = resultFrame.to_csv ('export_dataframeWithoutStemming.csv', index = None, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
